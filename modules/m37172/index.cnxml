<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:bib="http://bibtexml.sf.net/">
  <title>Introduction to compressive sensing</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m37172</md:content-id>
  <md:title>Introduction to compressive sensing</md:title>
  <md:abstract>Introduction to compressive sensing.  This course introduces the basic concepts in compressive sensing. We overview the concepts of sparsity, compressibility, and transform coding. We then review applications of sparsity in several signal processing problems such as sparse recovery, model selection, data coding, and error correction. We overview the key results in these fields, focusing primarily on both theory and algorithms for sparse recovery. We also discuss applications of compressive sensing in communications, biosensing, medical imaging, and sensor networks.</md:abstract>
  <md:uuid>961e3ae6-15b5-4808-9150-5ef056eacf90</md:uuid>
</metadata>

<content>
    <para id="id187492">We are in the midst of a digital revolution that is driving the development and deployment of new kinds of sensing systems with ever-increasing fidelity and resolution. The theoretical foundation of this revolution is the pioneering work of Kotelnikov, Nyquist, Shannon, and Whittaker on sampling continuous-time band-limited signals <link target-id="bid2"/>, <link target-id="bid1"/>, <link target-id="bid3"/>, <link target-id="bid0"/>. Their results demonstrate that signals, images, videos, and other data can be exactly recovered from a set of uniformly spaced samples taken at the so-called <emphasis effect="italics">Nyquist rate</emphasis> of twice the highest frequency present in the signal of interest. Capitalizing on this discovery, much of signal processing has moved from the analog to the digital domain and ridden the wave of Moore's law. Digitization has enabled the creation of sensing and processing systems that are more robust, flexible, cheaper and, consequently, more widely-used than their analog counterparts.</para>
    <para id="id187536">As a result of this success, the amount of data generated by sensing systems has grown from a trickle to a torrent. Unfortunately, in many important and emerging applications, the resulting Nyquist rate is so high that we end up with far too many samples. Alternatively, it may simply be too costly, or even physically impossible, to build devices capable of acquiring samples at the necessary rate. Thus, despite extraordinary advances in computational power, the acquisition and processing of signals in application areas such as imaging, video, medical imaging, remote surveillance, spectroscopy, and genomic data analysis continues to pose a tremendous challenge.</para>
    <para id="id187897">To address the logistical and computational challenges involved in dealing with such high-dimensional data, we often depend on compression, which aims at finding the most concise representation of a signal that is able to achieve a target level of acceptable distortion. One of the most popular techniques for signal compression is known as <emphasis effect="italics">transform coding</emphasis>, and typically relies on finding a basis or frame that provides <emphasis effect="italics">sparse</emphasis> or <emphasis effect="italics">compressible</emphasis> representations for signals in a class of interest. By a sparse representation, we mean that for a signal of length <m:math overflow="scroll"><m:mi>N</m:mi></m:math>, we can represent it with <m:math overflow="scroll"><m:mrow><m:mi>K</m:mi><m:mo>≪</m:mo><m:mi>N</m:mi></m:mrow></m:math> nonzero coefficients; by a compressible representation, we mean that the signal is well-approximated by a signal with only <m:math overflow="scroll"><m:mi>K</m:mi></m:math> nonzero coefficients. Both sparse and compressible signals can be represented with high fidelity by preserving only the values and locations of the largest coefficients of the signal. This process is called <emphasis effect="italics">sparse approximation</emphasis>, and forms the foundation of transform coding schemes that exploit signal sparsity and compressibility, including the JPEG, JPEG2000, MPEG, and MP3 standards.</para>
    <para id="id187975">Leveraging the concept of transform coding, <emphasis effect="italics">compressive sensing</emphasis> (CS) has emerged as a new framework for signal acquisition and sensor design.
CS enables a potentially large reduction in the sampling and computation costs for sensing signals that have a sparse or compressible representation. The Nyquist-Shannon sampling theorem states that a certain minimum number of samples is required in order to perfectly capture an arbitrary bandlimited signal, but when the signal is sparse in a known basis we can vastly reduce the number of measurements that need to be stored. Consequently, when sensing sparse signals we might be able to do better than suggested by classical results. This is the fundamental idea behind CS: rather than first sampling at a high rate and then compressing the sampled data, we would like to find ways to <emphasis effect="italics">directly</emphasis> sense the data in a compressed form — i.e., at a lower sampling rate. The field of CS grew out of the work of Emmanuel Candès, Justin Romberg, and Terence Tao and of David Donoho, who showed that a finite-dimensional signal having a sparse or compressible representation can be recovered from a small set of linear, nonadaptive measurements <link target-id="bid15"/>, <link target-id="bid13"/>, <link target-id="bid14"/>. The design of these measurement schemes and their extensions to practical data models and acquisition schemes are one of the most central challenges in the field of CS.</para>
    <para id="id188046">Although this idea has only recently gained significant attraction in the signal processing community, there have been hints in this direction dating back as far as the eighteenth century. In 1795, Prony proposed an algorithm for the estimation of the parameters associated with a small number of complex exponentials sampled in the presence of noise <link target-id="bid16"/>. The next theoretical leap came in the early 1900's, when Carathéodory showed that a positive linear combination of <emphasis effect="italics">any</emphasis> <m:math overflow="scroll"><m:mi>K</m:mi></m:math> sinusoids is uniquely determined by its value at <m:math overflow="scroll"><m:mrow><m:mi>t</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow></m:math> and at <emphasis effect="italics">any</emphasis> other <m:math overflow="scroll"><m:mrow><m:mn>2</m:mn><m:mi>K</m:mi></m:mrow></m:math> points in time <link target-id="bid17"/>, <link target-id="bid18"/>. This represents far fewer samples than the number of Nyquist-rate samples when <m:math overflow="scroll"><m:mi>K</m:mi></m:math> is small and the range of possible frequencies is large. In the 1990's, this work was generalized by George, Gorodnitsky, and Rao, who studied sparsity in the context of biomagnetic imaging and other contexts <link target-id="bid19"/>, <link target-id="bid20"/>, and by Bressler and Feng, who proposed a sampling scheme for acquiring certain classes of signals consisting of <m:math overflow="scroll"><m:mi>K</m:mi></m:math> components with nonzero bandwidth (as opposed to pure sinusoids) <link target-id="bid21"/>, <link target-id="bid23"/>. In the early 2000's Vetterli, Marziliano, and Blu proposed a sampling scheme for non-bandlimited signals that are governed by only <m:math overflow="scroll"><m:mi>K</m:mi></m:math> parameters, showing that these signals can be sampled and recovered from just <m:math overflow="scroll"><m:mrow><m:mn>2</m:mn><m:mi>K</m:mi></m:mrow></m:math> samples <link target-id="bid25"/>.</para>
    <para id="id188195">A related problem focuses on recovery of a signal from partial observation of its Fourier transform. Beurling proposed a method for extrapolating these observations to determine the entire Fourier transform <link target-id="bid26"/>. One can show that if the signal consists of a finite number of impulses, then Beurling's approach will correctly recover the entire Fourier transform (of this non-bandlimited signal) from <emphasis effect="italics">any</emphasis> sufficiently large piece of its Fourier transform. His approach — to find the signal with smallest <m:math overflow="scroll"><m:msub><m:mi>ℓ</m:mi><m:mn>1</m:mn></m:msub></m:math> norm among all signals agreeing with the acquired Fourier measurements — bears a remarkable resemblance to some of the algorithms used in CS.</para>
    <para id="id188232">More recently, Candès, Romberg, Tao <link target-id="bid13"/>, <link target-id="bid9"/>, <link target-id="bid10"/>, <link target-id="bid12"/>, <link target-id="bid11"/>, and Donoho <link target-id="bid14"/> showed that a signal having a sparse representation can be recovered <emphasis effect="italics">exactly</emphasis> from a small set of linear, nonadaptive measurements. This result suggests that it may be possible to sense sparse signals by taking far fewer measurements, hence the name <emphasis effect="italics">compressive</emphasis> sensing. Note, however, that CS differs from classical sampling in two important respects. First, rather than sampling the signal at specific points in time, CS systems typically acquire measurements in the form of inner products between the signal and more general test functions. We will see throughout this course that <emphasis effect="italics">randomness</emphasis> often plays a key role in the design of these test functions. Second, the two frameworks differ in the manner in which they deal with <emphasis effect="italics">signal recovery</emphasis>, i.e., the problem of recovering the original signal from the compressive measurements. In the Nyquist-Shannon framework, signal recovery is achieved through cardinal sine (sinc) interpolation — a linear process that requires little computation and has a simple interpretation.</para>
    <para id="id188299">CS has already had notable impact on several applications. One example is <link document="m37363" version="latest">medical imaging</link>, where it has enabled speedups by a factor of seven in pediatric MRI while preserving diagnostic quality <link target-id="bid31"/>. Moreover, the broad applicability of this framework has inspired research that extends the CS framework by proposing practical implementations for numerous applications, including <link document="m37375" version="latest">sub-Nyquist analog-to-digital converters</link> (ADCs), <link document="m37369" version="latest">compressive imaging architectures</link>, and <link document="m37373" version="latest">compressive sensor networks</link>.</para>
    <para id="id188420">This course introduces the basic concepts in compressive sensing. We overview the concepts of <link document="m37168" version="latest">sparsity</link>, <link document="m37166" version="latest">compressibility</link>, and transform coding.  We overview the key results in the field, beginning by focusing primarily on the theory of <link document="m37169" version="latest">sensing matrix design</link>, <link document="m37179" version="latest"><m:math overflow="scroll"><m:msub><m:mi>ℓ</m:mi><m:mn>1</m:mn></m:msub></m:math>-minimization</link>, and alternative algorithms for <link document="m37292" version="latest">sparse recovery</link>. We then review applications of sparsity in several signal processing problems such as <link document="m37360" version="latest">sparse regression and model selection</link>, <link document="m37361" version="latest">error correction</link>, <link document="m37362" version="latest">group testing</link>, and <link document="m37372" version="latest">compressive inference</link>.  We also discuss applications of compressive sensing in <link document="m37375" version="latest">analog-to-digital conversion</link>, <link document="m37374" version="latest">biosensing</link>, <link document="m37369" version="latest">conventional</link> and <link document="m37370" version="latest">hyperspectral</link> imaging, <link document="m37363" version="latest">medical imaging</link>, and <link document="m37373" version="latest">sensor networks</link>.

</para><section id="eip-422"><title>Acknowledgments</title><para id="eip-160">The authors would like to thank Ewout van den Berg, Yonina Eldar, Piotr Indyk, Gitta Kutyniok, and Yaniv Plan for their feedback regarding some portions of this course which now also appear in the <link url="http://www-stat.stanford.edu/~markad/publications/ddek-chapter1-2011.pdf">introductory chapter</link> of <emphasis effect="italics">Compressed Sensing: Theory and Applications</emphasis>, Cambridge University Press, 2011.  
</para></section>
  </content>
  <bib:file>
    <bib:entry id="bid15">
      <bib:article>
        <!--required fields-->
        <bib:author>Baraniuk, R.</bib:author>
        <bib:title>Compressive sensing</bib:title>
        <bib:journal>IEEE Signal Processing Mag.</bib:journal>
        <bib:year>2007</bib:year>
        <!--optional fields-->
        <bib:volume>24</bib:volume>
        <bib:number>4</bib:number>
        <bib:pages>118–120, 124</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid26">
      <bib:inproceedings>
        <!--required fields-->
        <bib:author>Beurling, A.</bib:author>
        <bib:title>Sur les intégrales de Fourier absolument convergentes et leur application à une transformation fonctionelle</bib:title>
        <bib:booktitle>Proc. Scandinavian Math. Congress</bib:booktitle>
        <bib:year>1938</bib:year>
        <!--optional fields-->
        <bib:editor/>
        <bib:number/>
        <bib:series/>
        <bib:pages/>
        <bib:address>Helsinki, Finland</bib:address>
        <bib:month/>
        <bib:organization/>
        <bib:publisher/>
        <bib:note/>
      </bib:inproceedings>
    </bib:entry>
    <bib:entry id="bid17">
      <bib:article>
        <!--required fields-->
        <bib:author>Carathéodory, C.</bib:author>
        <bib:title>Über den Variabilitätsbereich der Koeffizienten von Potenzreihen, die gegebene Werte nicht annehmen</bib:title>
        <bib:journal>Math. Ann.</bib:journal>
        <bib:year>1907</bib:year>
        <!--optional fields-->
        <bib:volume>64</bib:volume>
        <bib:number/>
        <bib:pages>95–115</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid18">
      <bib:article>
        <!--required fields-->
        <bib:author>Carathéodory, C.</bib:author>
        <bib:title>Über den Variabilitätsbereich der Fourierschen Konstanten von positiven harmonischen Funktionen</bib:title>
        <bib:journal>Rend. Circ. Mat. Palermo</bib:journal>
        <bib:year>1911</bib:year>
        <!--optional fields-->
        <bib:volume>32</bib:volume>
        <bib:number/>
        <bib:pages>193–217</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid13">
      <bib:inproceedings>
        <!--required fields-->
        <bib:author>Candès, E.</bib:author>
        <bib:title>Compressive sampling</bib:title>
        <bib:booktitle>Proc. Int. Congress of Math.</bib:booktitle>
        <bib:year>2006</bib:year>
        <!--optional fields-->
        <bib:editor/>
        <bib:number/>
        <bib:series/>
        <bib:pages/>
        <bib:address>Madrid, Spain</bib:address>
        <bib:month>Aug.</bib:month>
        <bib:organization/>
        <bib:publisher/>
        <bib:note/>
      </bib:inproceedings>
    </bib:entry>
    <bib:entry id="bid9">
      <bib:article>
        <!--required fields-->
        <bib:author>Candès, E. and Romberg, J.</bib:author>
        <bib:title>Quantitative robust uncertainty principles and optimally sparse decompositions</bib:title>
        <bib:journal>Found. Comput. Math.</bib:journal>
        <bib:year>2006</bib:year>
        <!--optional fields-->
        <bib:volume>6</bib:volume>
        <bib:number>2</bib:number>
        <bib:pages>227–254</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid10">
      <bib:article>
        <!--required fields-->
        <bib:author>Candès, E. and Romberg, J. and Tao, T.</bib:author>
        <bib:title>Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information</bib:title>
        <bib:journal>IEEE Trans. Inform. Theory</bib:journal>
        <bib:year>2006</bib:year>
        <!--optional fields-->
        <bib:volume>52</bib:volume>
        <bib:number>2</bib:number>
        <bib:pages>489–509</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid12">
      <bib:article>
        <!--required fields-->
        <bib:author>Candès, E. and Romberg, J. and Tao, T.</bib:author>
        <bib:title>Stable signal recovery from incomplete and inaccurate measurements</bib:title>
        <bib:journal>Comm. Pure Appl. Math.</bib:journal>
        <bib:year>2006</bib:year>
        <!--optional fields-->
        <bib:volume>59</bib:volume>
        <bib:number>8</bib:number>
        <bib:pages>1207–1223</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid11">
      <bib:article>
        <!--required fields-->
        <bib:author>Candès, E. and Tao, T.</bib:author>
        <bib:title>Near Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?</bib:title>
        <bib:journal>IEEE Trans. Inform. Theory</bib:journal>
        <bib:year>2006</bib:year>
        <!--optional fields-->
        <bib:volume>52</bib:volume>
        <bib:number>12</bib:number>
        <bib:pages>5406–5425</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid14">
      <bib:article>
        <!--required fields-->
        <bib:author>Donoho, D.</bib:author>
        <bib:title>Compressed sensing</bib:title>
        <bib:journal>IEEE Trans. Inform. Theory</bib:journal>
        <bib:year>2006</bib:year>
        <!--optional fields-->
        <bib:volume>52</bib:volume>
        <bib:number>4</bib:number>
        <bib:pages>1289–1306</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid21">
      <bib:inproceedings>
        <!--required fields-->
        <bib:author>Feng, P. and Bresler, Y.</bib:author>
        <bib:title>Spectrum-blind minimum-rate sampling and reconstruction of multiband signals</bib:title>
        <bib:booktitle>Proc. IEEE Int. Conf. Acoust., Speech, and Signal Processing (ICASSP)</bib:booktitle>
        <bib:year>1996</bib:year>
        <!--optional fields-->
        <bib:editor/>
        <bib:number/>
        <bib:series/>
        <bib:pages/>
        <bib:address>Atlanta, GA</bib:address>
        <bib:month>May</bib:month>
        <bib:organization/>
        <bib:publisher/>
        <bib:note/>
      </bib:inproceedings>
    </bib:entry>
    <bib:entry id="bid23">
      <bib:phdthesis>
        <!--required fields-->
        <bib:author>Feng, P.</bib:author>
        <bib:title>Universal spectrum blind minimum rate sampling and reconstruction of multiband signals</bib:title>
        <bib:school>University of Illinois at Urbana-Champaign</bib:school>
        <bib:year>1997</bib:year>
        <!--optional fields-->
        <bib:type>Ph. D. Thesis</bib:type>
        <bib:address/>
        <bib:month>Mar.</bib:month>
        <bib:note/>
      </bib:phdthesis>
    </bib:entry>
    <bib:entry id="bid19">
      <bib:inproceedings>
        <!--required fields-->
        <bib:author>Gorodnitsky, I. and Rao, B. and George, J.</bib:author>
        <bib:title>Source Localization in Magnetoencephalagraphy using an Iterative Weighted Minimum Norm Algorithm</bib:title>
        <bib:booktitle>Proc. Asilomar Conf. Signals, Systems, and Computers</bib:booktitle>
        <bib:year>1992</bib:year>
        <!--optional fields-->
        <bib:editor/>
        <bib:number/>
        <bib:series/>
        <bib:pages/>
        <bib:address>Pacific Grove, CA</bib:address>
        <bib:month>Oct.</bib:month>
        <bib:organization/>
        <bib:publisher/>
        <bib:note/>
      </bib:inproceedings>
    </bib:entry>
    <bib:entry id="bid2">
      <bib:inproceedings>
        <!--required fields-->
        <bib:author>Kotelnikov, V.</bib:author>
        <bib:title>On the carrying capacity of the ether and wire in telecommunications</bib:title>
        <bib:booktitle>Izd. Red. Upr. Svyazi RKKA</bib:booktitle>
        <bib:year>1933</bib:year>
        <!--optional fields-->
        <bib:editor/>
        <bib:number/>
        <bib:series/>
        <bib:pages/>
        <bib:address>Moscow, Russia</bib:address>
        <bib:month/>
        <bib:organization/>
        <bib:publisher/>
        <bib:note/>
      </bib:inproceedings>
    </bib:entry>
    <bib:entry id="bid1">
      <bib:article>
        <!--required fields-->
        <bib:author>Nyquist, H.</bib:author>
        <bib:title>Certain topics in telegraph transmission theory</bib:title>
        <bib:journal>Trans. AIEE</bib:journal>
        <bib:year>1928</bib:year>
        <!--optional fields-->
        <bib:volume>47</bib:volume>
        <bib:number/>
        <bib:pages>617–644</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid16">
      <bib:article>
        <!--required fields-->
        <bib:author>Prony, R.</bib:author>
        <bib:title>Essai expérimental et analytique sur les lois de la Dilatabilité des fluides élastiques et sur celles de la Force expansive de la vapeur de l'eau et de la vapeur de l'alkool, à différentes températures</bib:title>
        <bib:journal>J. de l'École Polytechnique, Floréal et Prairial III</bib:journal>
        <bib:year>1795</bib:year>
        <!--optional fields-->
        <bib:volume>1</bib:volume>
        <bib:number>2</bib:number>
        <bib:pages>24–76</bib:pages>
        <bib:month/>
        <bib:note>R. Prony is Gaspard Riche, baron de Prony</bib:note>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid20">
      <bib:inproceedings>
        <!--required fields-->
        <bib:author>Rao, B.</bib:author>
        <bib:title>Signal Processing with the Sparseness Constraint</bib:title>
        <bib:booktitle>Proc. IEEE Int. Conf. Acoust., Speech, and Signal Processing (ICASSP)</bib:booktitle>
        <bib:year>1998</bib:year>
        <!--optional fields-->
        <bib:editor/>
        <bib:number/>
        <bib:series/>
        <bib:pages/>
        <bib:address>Seattle, WA</bib:address>
        <bib:month>May</bib:month>
        <bib:organization/>
        <bib:publisher/>
        <bib:note/>
      </bib:inproceedings>
    </bib:entry>
    <bib:entry id="bid3">
      <bib:article>
        <!--required fields-->
        <bib:author>Shannon, C.</bib:author>
        <bib:title>Communication in the presence of noise</bib:title>
        <bib:journal>Proc. Institute of Radio Engineers</bib:journal>
        <bib:year>1949</bib:year>
        <!--optional fields-->
        <bib:volume>37</bib:volume>
        <bib:number>1</bib:number>
        <bib:pages>10–21</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid31">
      <bib:inproceedings>
        <!--required fields-->
        <bib:author>Vasanawala, S. and Alley, M. and Barth, R. and Hargreaves, B. and Pauly, J. and Lustig, M.</bib:author>
        <bib:title>Faster Pediatric MRI Via Compressed Sensing</bib:title>
        <bib:booktitle>Proc. Annual Meeting Soc. Pediatric Radiology (SPR)</bib:booktitle>
        <bib:year>2009</bib:year>
        <!--optional fields-->
        <bib:editor/>
        <bib:number/>
        <bib:series/>
        <bib:pages/>
        <bib:address>Carlsbad, CA</bib:address>
        <bib:month>Apr.</bib:month>
        <bib:organization/>
        <bib:publisher/>
        <bib:note/>
      </bib:inproceedings>
    </bib:entry>
    <bib:entry id="bid25">
      <bib:article>
        <!--required fields-->
        <bib:author>Vetterli, M. and Marziliano, P. and Blu, T.</bib:author>
        <bib:title>Sampling signals with finite rate of innovation</bib:title>
        <bib:journal>IEEE Trans. Signal Processing</bib:journal>
        <bib:year>2002</bib:year>
        <!--optional fields-->
        <bib:volume>50</bib:volume>
        <bib:number>6</bib:number>
        <bib:pages>1417–1428</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
    <bib:entry id="bid0">
      <bib:article>
        <!--required fields-->
        <bib:author>Whittaker, E.</bib:author>
        <bib:title>On the Functions Which are Represented by the Expansions of the Interpolation Theory</bib:title>
        <bib:journal>Proc. Royal Soc. Edinburgh, Sec. A</bib:journal>
        <bib:year>1915</bib:year>
        <!--optional fields-->
        <bib:volume>35</bib:volume>
        <bib:number/>
        <bib:pages>181–194</bib:pages>
        <bib:month/>
        <bib:note/>
      </bib:article>
    </bib:entry>
  </bib:file>
</document>